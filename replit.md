# Peterson Family Insurance AI Phone System

## üìã **CURRENT STATUS**

### **Production System** - Fully Operational
- **Platform**: DigitalOcean Droplet with Docker
- **Performance**: 2-2.5 second response times achieved
- **Architecture**: Microservices (Flask + FastAPI + AI-Memory service)
- **Status**: ‚úÖ **PRODUCTION READY** with completed microservices migration

## Overview
This project is an AI-powered phone system for Peterson Family Insurance, utilizing "Samantha" as the AI agent. The system, built on NeuroSphere Orchestrator, is a FastAPI-based solution designed for intelligent call handling with persistent memory. It aims for a rapid response time of 2-2.5 seconds. Key capabilities include maintaining conversation continuity via HTTP-based AI-Memory service, integrating external tools for actions, and employing safety modes for content filtering. The orchestrator serves as middleware between Twilio voice calls and Language Learning Models (LLMs), enhancing conversations through memory retrieval, prompt engineering, and extensible tool functionality.

**‚úÖ LATEST MAJOR ACHIEVEMENTS:**

- **Sept 25, 2025**: ‚úÖ **MICROSERVICES MIGRATION COMPLETE** - Successfully migrated all admin settings from config.json to ai-memory service, implementing true microservices architecture with centralized configuration management
- **Sept 13, 2025**: ‚úÖ **MEMORY SYSTEM OVERHAUL** - Migrated from direct PostgreSQL to HTTP-based AI-Memory service, eliminating "degraded mode" issues
- **Current**: ‚úÖ **LLM MIGRATION COMPLETE** - Fully migrated from RunPod to OpenAI Realtime API (gpt-realtime-2025-08-28)

## User Preferences
Preferred communication style: Simple, everyday language.

## System Architecture
**‚úÖ MICROSERVICES ARCHITECTURE (Completed Sept 25, 2025)**

The system now operates as a true microservices architecture with complete separation of concerns:

1. **Phone System (ChatStack)**: Flask orchestrator (`main.py`) handles Twilio webhooks
2. **AI Engine**: FastAPI backend (`app/main.py`) manages LLM integration and conversation flow
3. **AI-Memory Service**: External HTTP service (http://209.38.143.71:8100) handles all persistent memory and admin configuration

**Configuration Flow**: Admin Panel ‚Üí AI-Memory Service ‚Üí Phone System ‚Üí Twilio Calls

**Key Improvement**: All admin settings (greetings, voice settings, AI instructions) are now stored in the ai-memory service instead of local config files, enabling dynamic configuration without code deployment.

## ‚ö†Ô∏è CRITICAL: Environment Configuration

**NEVER TOUCH /opt/ChatStack/.env FILE**
- The `/opt/ChatStack/.env` file on DigitalOcean server contains all production secrets and is properly configured
- This file should NEVER be deleted, overwritten, or modified by scripts or agents
- All secrets are properly set in this file and working correctly
- Any issues should be debugged WITHOUT touching this file
- Architecture: Secrets in .env file, non-secrets in config.json

### Current Production Secrets (in .env file):
- DATABASE_URL, PGHOST, PGPORT, PGDATABASE, PGUSER, PGPASSWORD
- TWILIO_ACCOUNT_SID, TWILIO_AUTH_TOKEN, TWILIO_PHONE_NUMBER
- ELEVENLABS_API_KEY, ELEVENLABS_VOICE_ID
- OPENAI_API_KEY, LLM_BASE_URL, SESSION_SECRET
- DEEPGRAM_API, HUGGINHFACE_TOKEN

### Core Components:
- **LLM Integration**: ‚úÖ **FULLY MIGRATED TO OPENAI** - Uses OpenAI Realtime API (gpt-realtime-2025-08-28) for AI responses with 2-2.5 second response times. Completely replaced previous RunPod integration.

- **Memory System**: ‚úÖ **HYBRID ARCHITECTURE (Oct 1, 2025)** - Dual-layer memory system for optimal conversation continuity:
  
  **Layer 1: Rolling Thread History (In-Process)**
  - FastAPI maintains `THREAD_HISTORY` deque (maxlen=100) per stable `thread_id`
  - Thread ID format: `user_{phone_number}` (e.g., `user_9495565377`)
  - Provides within-call AND cross-call conversation continuity
  - Survives container uptime, resets on restart
  
  **Layer 2: AI-Memory Service (Durable Storage)**
  - HTTP-based service at http://209.38.143.71:8100
  - Stores structured facts: person, preference, project, rule, moment, fact
  - Handles admin settings (greetings, voice settings, AI instructions)
  - User registration and caller management
  - Robust HTTPMemoryStore with concatenated JSON parser
  - Optional durable recap per thread (1-paragraph summary)
  
  **Implementation Details:**
  - Flask (`main.py` line 686): Generates `thread_id = f"user_{user_id}"` instead of CallSid
  - FastAPI (`app/main.py` line 34): Maintains THREAD_HISTORY dict with deques
  - Memory parser (`app/http_memory.py` line 175-191): Parses newline-separated JSON format
  - Message storage (line 81): Sends full JSON content via `json.dumps(value)`
  
  **Benefits:**
  - Fast conversation flow without database queries every turn
  - Persistent facts survive server restarts
  - 200+ message history window (tunable via maxlen parameter)
  - Natural cross-call continuity (same thread_id = same history)

- **Prompt Engineering**: Employs file-based system prompts for AI personalities, intelligent context packing from memory, and safety triggers for content filtering.
- **Tool System**: An extensible, JSON schema-based architecture for external tool execution (e.g., meeting booking, message sending) with a central dispatcher and error recovery.
- **Data Models**: Pydantic for type-safe validation of request/response models, including role-based messages and structured memory objects.
- **Safety & Security**: Features multi-tier content filtering, PII protection, rate limiting, and comprehensive input validation.

### UI/UX Decisions:
- **Admin Panel**: Web interface at `/admin.html` provides full control over:
  - Greeting messages for different caller types
  - Voice settings and AI personality
  - System configuration via ai-memory service
- **Voice-First Design**: Seamless voice interaction with ElevenLabs TTS integration
- **Real-time Updates**: Admin changes take effect immediately without code deployment

### Technical Implementations:
- **Python Frameworks**: Flask and FastAPI.
- **Database**: PostgreSQL with `pgvector` for vector embeddings and `pgcrypto` for UUIDs.
- **Containerization**: Docker for deployment, with `docker-compose.yml` for orchestration.
- **Web Server**: Nginx for HTTPS termination, proxying requests to the Flask and FastAPI services.
- **Deployment**: Primarily on DigitalOcean Droplets with OpenAI API for LLM inference.

## External Dependencies

### Services:
- **Twilio**: For voice call management and incoming call webhooks.
- **OpenAI API**: Primary LLM service using GPT Realtime model (`https://api.openai.com/v1/chat/completions`).
- **ElevenLabs**: For natural voice synthesis and text-to-speech conversion.
- **AI-Memory Service**: An external service for conversation memory persistence (`http://209.38.143.71:8100`).

### Databases:
- **PostgreSQL**: Used with `pgvector` extension for conversation memory and semantic search.

### Libraries (Key Examples):
- **FastAPI** & **Uvicorn**: Web framework and ASGI server.
- **Pydantic**: Data validation.
- **NumPy**: Vector operations.
- **Requests**: HTTP client.
- **psycopg2**: PostgreSQL adapter.

### Optional Integrations (Planned/Recommended):
- **Redis**: For production short-term memory.
- **Embedding Services**: Such as OpenAI Embeddings or Sentence Transformers for production embedding generation.

---

## Nginx Configuration Management

### **Check Active Configurations**
```bash
ls /etc/nginx/sites-enabled/
```

**Expected configurations:**
- `voice-theinsurancedoctors-com.conf` ‚Üí AI Phone System
- `neurosphere-llms.conf` ‚Üí Legacy config (should serve different domain or be removed)

### **Rules**
1. **Only one config** should claim `server_name voice.theinsurancedoctors.com`
2. **The `voice-theinsurancedoctors-com.conf`** must contain both `/phone/` and `/static/` proxy blocks:
   ```nginx
   location /phone/ {
       proxy_pass http://127.0.0.1:5000/phone/;
       proxy_set_header Host $host;
       proxy_set_header X-Real-IP $remote_addr;
       proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
       proxy_set_header X-Forwarded-Proto $scheme;
   }

   location /static/ {
       proxy_pass http://127.0.0.1:5000/static/;
       proxy_set_header Host $host;
       proxy_set_header X-Real-IP $remote_addr;
       proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
       proxy_set_header X-Forwarded-Proto $scheme;
   }
   ```
3. **`neurosphere-llms.conf`** is legacy config - should serve different hostname or be removed (RunPod no longer used)

### **Conflict Detection**
```bash
# Check what neurosphere-llms.conf serves
sudo cat /etc/nginx/sites-enabled/neurosphere-llms.conf | grep -E "server_name|listen|default_server"
```

**Action Rules:**
- **Keep it** if it serves different domain
- **Disable it** if it references `voice.theinsurancedoctors.com` or has `default_server`

### **Deployment Commands**
```bash
# Deploy canonical config
sudo cp /opt/ChatStack/deploy/nginx/voice-theinsurancedoctors-com.conf /etc/nginx/sites-enabled/

# Remove conflicts (only if they claim same domain)
sudo rm /etc/nginx/sites-enabled/default  # if exists
sudo rm /etc/nginx/sites-enabled/neurosphere-llms.conf  # legacy RunPod config, remove if conflicts

# Test and reload
sudo nginx -t
sudo systemctl reload nginx
```

### **Verification**
```bash
# Test static files proxied correctly
curl -I https://voice.theinsurancedoctors.com/static/audio/
# Should return: HTTP/1.1 200 OK (not 404)

# Test phone endpoint
curl -X POST https://voice.theinsurancedoctors.com/phone/incoming -d "test=1"
# Should return TwiML with HTTPS URLs
```

---

## Troubleshooting Checklist

### **Call Hangs Up Issues**
1. ‚úÖ **Memory System**: Fixed - HTTP-based AI-Memory service working perfectly 
2. ‚úì **Check for multiple nginx configurations causing conflicts**:
   ```bash
   ls /etc/nginx/sites-enabled/
   # Should prioritize: voice-theinsurancedoctors-com.conf
   # Check conflicts: sudo cat /etc/nginx/sites-enabled/neurosphere-llms.conf | grep -E "server_name|default_server"
   ```
3. ‚úì **Verify `/static/` proxy is configured** for audio file access:
   ```bash
   curl -I https://voice.theinsurancedoctors.com/static/audio/
   # Should return 200 OK, not 404
   ```
4. ‚úì Check nginx proxy configuration for `/phone/` location
5. ‚úì Verify Flask app responding: `curl http://localhost:5000/phone/incoming`
6. ‚úì Check Docker container logs: `docker logs chatstack-web-1`
7. ‚úì Test HTTPS endpoint: `curl https://voice.theinsurancedoctors.com/phone/incoming`

### **Current Status (Sept 25, 2025)**
- ‚úÖ **MICROSERVICES MIGRATION**: Complete - all admin settings in ai-memory service
- ‚úÖ **Memory System**: Fully operational with HTTP-based AI-Memory service
- ‚úÖ **LLM Integration**: OpenAI Realtime API (https://api.openai.com/v1) - RunPod completely removed
- ‚úÖ **Admin Panel**: Dynamic configuration via web interface
- ‚úÖ **User Registration**: Automatic caller registration with persistent memory
- **Performance**: Achieving 2-2.5 second response times in production

### **Voice Issues**
1. ‚úì Verify `ELEVENLABS_API_KEY` is set
2. ‚úì Check `/static/audio/` directory permissions
3. ‚úì Test ElevenLabs integration in logs
4. ‚úì Fallback to Twilio voice if ElevenLabs fails

### **AI Response Issues**
1. ‚úì Verify OpenAI API endpoint: `https://api.openai.com/v1`
2. ‚úì Check `OPENAI_API_KEY` environment variable
3. ‚úì Check `LLM_BASE_URL` environment variable
4. ‚úì Test LLM connection in startup logs